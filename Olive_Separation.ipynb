{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Olive_Separation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1F6iq5HMd15TZbjKyZN5St02Abiowwx8M",
      "authorship_tag": "ABX9TyPNb0+VNNUWiObxZZ6TQTfc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaterynaZakharova/Olive-Separation-With-TensorFlow-Object-Detection-API/blob/main/Olive_Separation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TkHDJMAkR3C"
      },
      "source": [
        "**Installation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6DuxaGVyneT"
      },
      "source": [
        "import os\r\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/Olive Separation/models/research/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAOzN5t9yuCp"
      },
      "source": [
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJwuTBoIy0Rh"
      },
      "source": [
        "import sys\r\n",
        "sys.path.append('content/drive/MyDrive/Colab Notebooks/Olive Separation/models/research/slim')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qz_q0_T09gP3",
        "outputId": "7eb04a24-7639-4194-a19a-79610640e561"
      },
      "source": [
        "!pip install tf_slim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf_slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\r\u001b[K     |█                               | 10kB 18.1MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 6.0MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30kB 3.9MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40kB 3.7MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 81kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 92kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 358kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf_slim) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl1h6_R79xjg",
        "outputId": "961b4fdb-0d96-4528-d64d-2c03cf3628ee"
      },
      "source": [
        "!pip install pycocotools"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.6/dist-packages (2.0.2)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools) (51.1.2)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools) (3.2.2)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools) (0.29.21)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzoR-POq-D1c",
        "outputId": "6b2dfc1e-e7ce-43a1-bf0e-e68b25816c94"
      },
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/Olive Separation/models/research"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Olive Separation/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNy_89crArXI",
        "outputId": "9b10cec4-c47d-4b4d-a2b8-b293650904c6"
      },
      "source": [
        "!pip install ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/drive/MyDrive/Colab Notebooks/Olive Separation/models/research\n",
            "Requirement already satisfied: Pillow>=1.0 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (7.0.0)\n",
            "Requirement already satisfied: Matplotlib>=2.1 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython>=0.28.1 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.29.21)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (1.19.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->Matplotlib>=2.1->object-detection==0.1) (1.15.0)\n",
            "Building wheels for collected packages: object-detection\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-cp36-none-any.whl size=1390904 sha256=1d257dea41656607ce4fa7fe182d24df23a87f5bbf89a897a14e6b685866e548\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-evz81_xv/wheels/65/69/54/5c1683fdbb547b53afa0b28d8f3842b649c02d9c05b2bc2a34\n",
            "Successfully built object-detection\n",
            "Installing collected packages: object-detection\n",
            "Successfully installed object-detection-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq3oMt8Wcx-j"
      },
      "source": [
        "import os\r\n",
        "os.environ['PYTHONPATH'] += '/content/drive/MyDrive/Colab Notebooks/Olive Separation/models/research/:/content/drive/MyDrive/Colab Notebooks/Olive Separation/models/research/slim/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuYka_bdpeaV"
      },
      "source": [
        "import os\r\n",
        "os.environ['PYTHONPATH'] += \":/content/drive/MyDrive/Colab Notebooks/Olive Separation/models\"\r\n",
        "\r\n",
        "import sys\r\n",
        "sys.path.append(\"/content/drive/MyDrive/Colab Notebooks/Olive Separation/models\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBQcnFBOBW2r"
      },
      "source": [
        "!pip install lvis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lk3KAEHOkuKE"
      },
      "source": [
        "**Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85p146SoCKiZ",
        "outputId": "0b0907ea-b130-40a5-e395-844931ff9ecb"
      },
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/Olive Separation/models/research/object_detection"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Olive Separation/models/research/object_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BbUiwaFMp1t"
      },
      "source": [
        "# !python model_main_tf2.py \\\r\n",
        "#     --pipeline_config_path=training/ssd_efficientdet_d0_512x512_coco17_tpu-8.config \\\r\n",
        "#     --model_dir=training \\\r\n",
        "#     --alsologtostderr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "afM5oU79E-Yr"
      },
      "source": [
        "!python model_main_tf2.py \\\r\n",
        "    --pipeline_config_path=training/centernet_hg104_512x512_coco17_tpu-8.config \\\r\n",
        "    --model_dir=training \\\r\n",
        "    --alsologtostderr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l857lCBik__B"
      },
      "source": [
        "**Inference graph**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y7k_73TOcDN"
      },
      "source": [
        "#!python exporter_main_v2.py --trained_checkpoint_dir=training/ --pipeline_config_path=training/ssd_efficientdet_d0_512x512_coco17_tpu-8.config --output_directory inference_graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0yiHSBeFFxq"
      },
      "source": [
        "!python exporter_main_v2.py --trained_checkpoint_dir=training/ --pipeline_config_path=training/centernet_hg104_512x512_coco17_tpu-8.config --output_directory inference_graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qs0RkCullG-B"
      },
      "source": [
        "**Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RydtF1cOpg5L"
      },
      "source": [
        "import io\r\n",
        "import os\r\n",
        "import scipy.misc\r\n",
        "import numpy as np\r\n",
        "import six\r\n",
        "import time\r\n",
        "import glob\r\n",
        "from IPython.display import display\r\n",
        "\r\n",
        "from six import BytesIO\r\n",
        "\r\n",
        "import matplotlib\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from PIL import Image, ImageDraw, ImageFont\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "from object_detection.utils import ops as utils_ops\r\n",
        "from object_detection.utils import label_map_util\r\n",
        "from object_detection.utils import visualization_utils as vis_util\r\n",
        "\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "def image_to_array(path):\r\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\r\n",
        "  image = Image.open(BytesIO(img_data))\r\n",
        "  (im_width, im_height) = image.size\r\n",
        "  return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)\r\n",
        "\r\n",
        "category_index = label_map_util.create_category_index_from_labelmap('/content/drive/MyDrive/Colab Notebooks/Olive Separation/models/research/object_detection/training/labelmap.pbtxt', use_display_name=True)\r\n",
        "\r\n",
        "tf.keras.backend.clear_session()\r\n",
        "model = tf.saved_model.load('/content/drive/MyDrive/Colab Notebooks/Olive Separation/models/research/object_detection/inference_graph/saved_model')\r\n",
        "\r\n",
        "def inference_for_image(model, image):\r\n",
        "  image = np.asarray(image)\r\n",
        "  input_tensor = tf.convert_to_tensor(image)\r\n",
        "  input_tensor = input_tensor[tf.newaxis,...]\r\n",
        "\r\n",
        "  model_fn = model.signatures['serving_default']\r\n",
        "  output_dict = model_fn(input_tensor)\r\n",
        "\r\n",
        "  num_detections = int(output_dict.pop('num_detections'))\r\n",
        "  output_dict = {key:value[0, :num_detections].numpy() \r\n",
        "                 for key,value in output_dict.items()}\r\n",
        "  output_dict['num_detections'] = num_detections\r\n",
        "\r\n",
        "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\r\n",
        "   \r\n",
        "  if 'detection_masks' in output_dict:\r\n",
        "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\r\n",
        "              output_dict['detection_masks'], output_dict['detection_boxes'],\r\n",
        "               image.shape[0], image.shape[1])      \r\n",
        "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5, tf.uint8)\r\n",
        "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\r\n",
        "  return output_dict\r\n",
        "\r\n",
        "count_black = 0\r\n",
        "count_green = 0\r\n",
        "\r\n",
        "for image_path in glob.glob('*.jpg'):\r\n",
        "  image_np = image_to_array(image_path)\r\n",
        "  output_dict = inference_for_image(model, image_np)\r\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\r\n",
        "      image_np,\r\n",
        "      output_dict['detection_boxes'],\r\n",
        "      output_dict['detection_classes'],\r\n",
        "      output_dict['detection_scores'],\r\n",
        "      category_index,\r\n",
        "      instance_masks=output_dict.get('detection_masks_reframed', None),\r\n",
        "      use_normalized_coordinates=True,\r\n",
        "      line_thickness=3)\r\n",
        "  display(Image.fromarray(image_np))\r\n",
        "  for i in range(100):\r\n",
        "    if output_dict['detection_scores'][i] > 0.5:\r\n",
        "      if output_dict['detection_classes'][i] == 1:\r\n",
        "        count_black = count_black + 1\r\n",
        "      if output_dict['detection_classes'][i] == 2:\r\n",
        "        count_green = count_green + 1\r\n",
        "\r\n",
        "print(count_black, 'black olives')\r\n",
        "print(count_green, 'green olives')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbwpIrftQjeV"
      },
      "source": [
        "-----------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbJ1LD6JQnLN"
      },
      "source": [
        "Variant 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO2RfG070wHV"
      },
      "source": [
        "import matplotlib\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import os\r\n",
        "import random\r\n",
        "import io\r\n",
        "import imageio\r\n",
        "import glob\r\n",
        "import scipy.misc\r\n",
        "import numpy as np\r\n",
        "from six import BytesIO\r\n",
        "from PIL import Image, ImageDraw, ImageFont\r\n",
        "from IPython.display import display, Javascript\r\n",
        "from IPython.display import Image as IPyImage\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from object_detection.utils import label_map_util\r\n",
        "from object_detection.utils import config_util\r\n",
        "from object_detection.utils import visualization_utils as viz_utils\r\n",
        "from object_detection.utils import colab_utils\r\n",
        "from object_detection.builders import model_builder\r\n",
        "\r\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Htocnd630dX5"
      },
      "source": [
        "def load_image_into_numpy_array(path):\r\n",
        "  \"\"\"Load an image from file into a numpy array.\r\n",
        "\r\n",
        "  Puts image into numpy array to feed into tensorflow graph.\r\n",
        "  Note that by convention we put it into a numpy array with shape\r\n",
        "  (height, width, channels), where channels=3 for RGB.\r\n",
        "\r\n",
        "  Args:\r\n",
        "    path: a file path.\r\n",
        "\r\n",
        "  Returns:\r\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\r\n",
        "  \"\"\"\r\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\r\n",
        "  image = Image.open(BytesIO(img_data))\r\n",
        "  (im_width, im_height) = image.size\r\n",
        "  return np.array(image.getdata()).reshape(\r\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\r\n",
        "\r\n",
        "def plot_detections(image_np,\r\n",
        "                    boxes,\r\n",
        "                    classes,\r\n",
        "                    scores,\r\n",
        "                    category_index,\r\n",
        "                    figsize=(12, 16),\r\n",
        "                    image_name=None):\r\n",
        "  \"\"\"Wrapper function to visualize detections.\r\n",
        "\r\n",
        "  Args:\r\n",
        "    image_np: uint8 numpy array with shape (img_height, img_width, 3)\r\n",
        "    boxes: a numpy array of shape [N, 4]\r\n",
        "    classes: a numpy array of shape [N]. Note that class indices are 1-based,\r\n",
        "      and match the keys in the label map.\r\n",
        "    scores: a numpy array of shape [N] or None.  If scores=None, then\r\n",
        "      this function assumes that the boxes to be plotted are groundtruth\r\n",
        "      boxes and plot all boxes as black with no classes or scores.\r\n",
        "    category_index: a dict containing category dictionaries (each holding\r\n",
        "      category index `id` and category name `name`) keyed by category indices.\r\n",
        "    figsize: size for the figure.\r\n",
        "    image_name: a name for the image file.\r\n",
        "  \"\"\"\r\n",
        "  image_np_with_annotations = image_np.copy()\r\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\r\n",
        "      image_np_with_annotations,\r\n",
        "      boxes,\r\n",
        "      classes,\r\n",
        "      scores,\r\n",
        "      category_index,\r\n",
        "      use_normalized_coordinates=True,\r\n",
        "      min_score_thresh=0.8)\r\n",
        "  if image_name:\r\n",
        "    plt.imsave(image_name, image_np_with_annotations)\r\n",
        "  else:\r\n",
        "    plt.imshow(image_np_with_annotations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CSKLCrB02j-"
      },
      "source": [
        "train_image_dir = '/content/drive/MyDrive/Colab Notebooks/Olive Separation/models/research/object_detection/images/train/'\r\n",
        "train_images_np = []\r\n",
        "for i in range(1, 25):\r\n",
        "  if i not in (3, 10, 11, 16, 18):\r\n",
        "    image_path = os.path.join(train_image_dir, 'black_olive_' + str(i) + '.jpg')\r\n",
        "    train_images_np.append(load_image_into_numpy_array(image_path))\r\n",
        "\r\n",
        "# plt.rcParams['axes.grid'] = False\r\n",
        "# plt.rcParams['xtick.labelsize'] = False\r\n",
        "# plt.rcParams['ytick.labelsize'] = False\r\n",
        "# plt.rcParams['xtick.top'] = False\r\n",
        "# plt.rcParams['xtick.bottom'] = False\r\n",
        "# plt.rcParams['ytick.left'] = False\r\n",
        "# plt.rcParams['ytick.right'] = False\r\n",
        "# plt.rcParams['figure.figsize'] = [14, 7]\r\n",
        "\r\n",
        "# for idx, train_image_np in enumerate(train_images_np):\r\n",
        "#   plt.subplot(2, 3, idx+1)\r\n",
        "#   plt.imshow(train_image_np)\r\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "GKJC1gxm06KO",
        "outputId": "ef836af9-e235-4516-dcad-a1b980db3aeb"
      },
      "source": [
        "gt_boxes = []\r\n",
        "colab_utils.annotate(train_images_np, box_storage_pointer=gt_boxes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "              async function load_image(imgs, callbackId) {\n",
              "                  //init organizational elements\n",
              "                  const div = document.createElement('div');\n",
              "                  var image_cont = document.createElement('div');\n",
              "                  var errorlog = document.createElement('div');\n",
              "                  var crosshair_h = document.createElement('div');\n",
              "                  crosshair_h.style.position = \"absolute\";\n",
              "                  crosshair_h.style.backgroundColor = \"transparent\";\n",
              "                  crosshair_h.style.width = \"100%\";\n",
              "                  crosshair_h.style.height = \"0px\";\n",
              "                  crosshair_h.style.zIndex = 9998;\n",
              "                  crosshair_h.style.borderStyle = \"dotted\";\n",
              "                  crosshair_h.style.borderWidth = \"2px\";\n",
              "                  crosshair_h.style.borderColor = \"rgba(255, 0, 0, 0.75)\";\n",
              "                  crosshair_h.style.cursor = \"crosshair\";\n",
              "                  var crosshair_v = document.createElement('div');\n",
              "                  crosshair_v.style.position = \"absolute\";\n",
              "                  crosshair_v.style.backgroundColor = \"transparent\";\n",
              "                  crosshair_v.style.width = \"0px\";\n",
              "                  crosshair_v.style.height = \"100%\";\n",
              "                  crosshair_v.style.zIndex = 9999;\n",
              "                  crosshair_v.style.top = \"0px\";\n",
              "                  crosshair_v.style.borderStyle = \"dotted\";\n",
              "                  crosshair_v.style.borderWidth = \"2px\";\n",
              "                  crosshair_v.style.borderColor = \"rgba(255, 0, 0, 0.75)\";\n",
              "                  crosshair_v.style.cursor = \"crosshair\";\n",
              "                  crosshair_v.style.marginTop = \"23px\";\n",
              "                  var brdiv = document.createElement('br');\n",
              "\n",
              "\n",
              "                  //init control elements\n",
              "                  var next = document.createElement('button');\n",
              "                  var prev = document.createElement('button');\n",
              "                  var submit = document.createElement('button');\n",
              "                  var deleteButton = document.createElement('button');\n",
              "                  var deleteAllbutton = document.createElement('button');\n",
              "\n",
              "                  //init image containers\n",
              "                  var image = new Image();\n",
              "                  var canvas_img = document.createElement('canvas');\n",
              "                  var ctx = canvas_img.getContext(\"2d\");\n",
              "                  canvas_img.style.cursor = \"crosshair\";\n",
              "                  canvas_img.setAttribute('draggable', false);\n",
              "                  crosshair_v.setAttribute('draggable', false);\n",
              "                  crosshair_h.setAttribute('draggable', false);\n",
              "\n",
              "                  // bounding box containers\n",
              "                  const height = 600\n",
              "                  var allBoundingBoxes = [];\n",
              "                  var curr_image = 0\n",
              "                  var im_height = 0;\n",
              "                  var im_width = 0;\n",
              "\n",
              "                  //initialize bounding boxes\n",
              "                  for (var i = 0; i < imgs.length; i++) {\n",
              "                    allBoundingBoxes[i] = [];\n",
              "                  }\n",
              "                  //initialize image view\n",
              "                  errorlog.id = 'errorlog';\n",
              "                  image.style.display = 'block';\n",
              "                  image.setAttribute('draggable', false);\n",
              "\n",
              "                  //load the first image\n",
              "                  img = imgs[curr_image];\n",
              "                  image.src = \"data:image/png;base64,\" + img;\n",
              "                  image.onload = function() {\n",
              "                      // normalize display height and canvas\n",
              "                      image.height = height;\n",
              "                      image_cont.height = canvas_img.height = image.height;\n",
              "                      image_cont.width = canvas_img.width = image.naturalWidth;\n",
              "                      crosshair_v.style.height = image_cont.height + \"px\";\n",
              "                      crosshair_h.style.width = image_cont.width + \"px\";\n",
              "\n",
              "                      // draw the new image\n",
              "                      ctx.drawImage(image, 0, 0, image.naturalWidth, image.naturalHeight, 0, 0,  canvas_img.width,  canvas_img.height);\n",
              "\n",
              "                  };\n",
              "\n",
              "                  // move to next image in array\n",
              "                  next.textContent = \"next image\";\n",
              "                  next.onclick = function(){\n",
              "                      if (curr_image < imgs.length - 1){\n",
              "                          // clear canvas and load new image\n",
              "                          curr_image += 1;\n",
              "                          errorlog.innerHTML = \"\";\n",
              "                      }\n",
              "                      else{\n",
              "                          errorlog.innerHTML = \"All images completed!!\";\n",
              "                      }\n",
              "                      resetcanvas();\n",
              "                  }\n",
              "\n",
              "                  //move forward through list of images\n",
              "                  prev.textContent = \"prev image\"\n",
              "                  prev.onclick = function(){\n",
              "                      if (curr_image > 0){\n",
              "                          // clear canvas and load new image\n",
              "                          curr_image -= 1;\n",
              "                          errorlog.innerHTML = \"\";\n",
              "                      }\n",
              "                      else{\n",
              "                          errorlog.innerHTML = \"at the beginning\";\n",
              "                      }\n",
              "                      resetcanvas();\n",
              "                  }\n",
              "                  // on delete, deletes the last bounding box\n",
              "                  deleteButton.textContent = \"undo bbox\";\n",
              "                  deleteButton.onclick = function(){\n",
              "                    boundingBoxes.pop();\n",
              "                    ctx.clearRect(0, 0, canvas_img.width, canvas_img.height);\n",
              "                    image.src = \"data:image/png;base64,\" + img;\n",
              "                    image.onload = function() {\n",
              "                        ctx.drawImage(image, 0, 0, image.naturalWidth, image.naturalHeight, 0, 0,  canvas_img.width,  canvas_img.height);\n",
              "                        boundingBoxes.map(r => {drawRect(r)});\n",
              "                    };\n",
              "                  }\n",
              "                  // on all delete, deletes all of the bounding box\n",
              "                  deleteAllbutton.textContent = \"delete all\"\n",
              "                  deleteAllbutton.onclick = function(){\n",
              "                    boundingBoxes = [];\n",
              "                    ctx.clearRect(0, 0, canvas_img.width, canvas_img.height);\n",
              "                    image.src = \"data:image/png;base64,\" + img;\n",
              "                    image.onload = function() {\n",
              "                        ctx.drawImage(image, 0, 0, image.naturalWidth, image.naturalHeight, 0, 0,  canvas_img.width,  canvas_img.height);\n",
              "                        //boundingBoxes.map(r => {drawRect(r)});\n",
              "                    };\n",
              "                  }\n",
              "\n",
              "                  // on submit, send the boxes to display\n",
              "                  submit.textContent = \"submit\";\n",
              "                  submit.onclick = function(){\n",
              "                    errorlog.innerHTML = \"\";\n",
              "\n",
              "                    // send box data to callback fucntion\n",
              "                    google.colab.kernel.invokeFunction(callbackId, [allBoundingBoxes], {});\n",
              "                  }\n",
              "\n",
              "                // init template for annotations\n",
              "                const annotation = {\n",
              "                      x: 0,\n",
              "                      y: 0,\n",
              "                      w: 0,\n",
              "                      h: 0,\n",
              "                };\n",
              "\n",
              "                // the array of all rectangles\n",
              "                let boundingBoxes = allBoundingBoxes[curr_image];\n",
              "\n",
              "                // the actual rectangle, the one that is being drawn\n",
              "                let o = {};\n",
              "\n",
              "                // a variable to store the mouse position\n",
              "                let m = {},\n",
              "\n",
              "                // a variable to store the point where you begin to draw the\n",
              "                // rectangle\n",
              "                start = {};\n",
              "\n",
              "                // a boolean variable to store the drawing state\n",
              "                let isDrawing = false;\n",
              "                var elem = null;\n",
              "\n",
              "                function handleMouseDown(e) {\n",
              "                  // on mouse click set change the cursor and start tracking the mouse position\n",
              "                  start = oMousePos(canvas_img, e);\n",
              "\n",
              "                  // configure is drawing to true\n",
              "                  isDrawing = true;\n",
              "                }\n",
              "\n",
              "                function handleMouseMove(e) {\n",
              "                    // move crosshairs, but only within the bounds of the canvas\n",
              "                    if (document.elementsFromPoint(e.pageX, e.pageY).includes(canvas_img)) {\n",
              "                      crosshair_h.style.top = e.pageY + \"px\";\n",
              "                      crosshair_v.style.left = e.pageX + \"px\";\n",
              "                    }\n",
              "\n",
              "                    // move the bounding box\n",
              "                    if(isDrawing){\n",
              "                      m = oMousePos(canvas_img, e);\n",
              "                      draw();\n",
              "                    }\n",
              "                }\n",
              "\n",
              "                function handleMouseUp(e) {\n",
              "                    if (isDrawing) {\n",
              "                        // on mouse release, push a bounding box to array and draw all boxes\n",
              "                        isDrawing = false;\n",
              "\n",
              "                        const box = Object.create(annotation);\n",
              "\n",
              "                        // calculate the position of the rectangle\n",
              "                        if (o.w > 0){\n",
              "                          box.x = o.x;\n",
              "                        }\n",
              "                        else{\n",
              "                          box.x = o.x + o.w;\n",
              "                        }\n",
              "                        if (o.h > 0){\n",
              "                          box.y = o.y;\n",
              "                        }\n",
              "                        else{\n",
              "                          box.y = o.y + o.h;\n",
              "                        }\n",
              "                        box.w = Math.abs(o.w);\n",
              "                        box.h = Math.abs(o.h);\n",
              "\n",
              "                        // add the bounding box to the image\n",
              "                        boundingBoxes.push(box);\n",
              "                        draw();\n",
              "                    }\n",
              "                }\n",
              "\n",
              "                function draw() {\n",
              "                    o.x = (start.x)/image.width;  // start position of x\n",
              "                    o.y = (start.y)/image.height;  // start position of y\n",
              "                    o.w = (m.x - start.x)/image.width;  // width\n",
              "                    o.h = (m.y - start.y)/image.height;  // height\n",
              "\n",
              "                    ctx.clearRect(0, 0, canvas_img.width, canvas_img.height);\n",
              "                    ctx.drawImage(image, 0, 0, image.naturalWidth, image.naturalHeight, 0, 0,  canvas_img.width,  canvas_img.height);\n",
              "                    // draw all the rectangles saved in the rectsRy\n",
              "                    boundingBoxes.map(r => {drawRect(r)});\n",
              "                    // draw the actual rectangle\n",
              "                    drawRect(o);\n",
              "                }\n",
              "\n",
              "                // add the handlers needed for dragging\n",
              "                crosshair_h.addEventListener(\"mousedown\", handleMouseDown);\n",
              "                crosshair_v.addEventListener(\"mousedown\", handleMouseDown);\n",
              "                document.addEventListener(\"mousemove\", handleMouseMove);\n",
              "                document.addEventListener(\"mouseup\", handleMouseUp);\n",
              "\n",
              "\n",
              "                function resetcanvas(){\n",
              "                    // clear canvas\n",
              "                    ctx.clearRect(0, 0, canvas_img.width, canvas_img.height);\n",
              "                    img = imgs[curr_image]\n",
              "                    image.src = \"data:image/png;base64,\" + img;\n",
              "\n",
              "                    // onload init new canvas and display image\n",
              "                    image.onload = function() {\n",
              "                        // normalize display height and canvas\n",
              "                        image.height = height;\n",
              "                        image_cont.height = canvas_img.height = image.height;\n",
              "                        image_cont.width = canvas_img.width = image.naturalWidth;\n",
              "                        crosshair_v.style.height = image_cont.height + \"px\";\n",
              "                        crosshair_h.style.width = image_cont.width + \"px\";\n",
              "\n",
              "                        // draw the new image\n",
              "                        ctx.drawImage(image, 0, 0, image.naturalWidth, image.naturalHeight, 0, 0,  canvas_img.width,  canvas_img.height);\n",
              "\n",
              "                        // draw bounding boxes\n",
              "                        boundingBoxes = allBoundingBoxes[curr_image];\n",
              "                        boundingBoxes.map(r => {drawRect(r)});\n",
              "                    };\n",
              "                }\n",
              "\n",
              "                function drawRect(o){\n",
              "                    // draw a predefined rectangle\n",
              "                    ctx.strokeStyle = \"red\";\n",
              "                    ctx.lineWidth = 2;\n",
              "                    ctx.beginPath(o);\n",
              "                    ctx.rect(o.x * image.width, o.y * image.height, o.w * image.width, o.h * image.height);\n",
              "                    ctx.stroke();\n",
              "                }\n",
              "\n",
              "                // Function to detect the mouse position\n",
              "                function oMousePos(canvas_img, evt) {\n",
              "                  let ClientRect = canvas_img.getBoundingClientRect();\n",
              "                    return {\n",
              "                      x: evt.clientX - ClientRect.left,\n",
              "                      y: evt.clientY - ClientRect.top\n",
              "                    };\n",
              "                }\n",
              "\n",
              "\n",
              "                //configure colab output display\n",
              "                google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "                //build the html document that will be seen in output\n",
              "                div.appendChild(document.createElement('br'))\n",
              "                div.appendChild(image_cont)\n",
              "                image_cont.appendChild(canvas_img)\n",
              "                image_cont.appendChild(crosshair_h)\n",
              "                image_cont.appendChild(crosshair_v)\n",
              "                div.appendChild(document.createElement('br'))\n",
              "                div.appendChild(errorlog)\n",
              "                div.appendChild(prev)\n",
              "                div.appendChild(next)\n",
              "                div.appendChild(deleteButton)\n",
              "                div.appendChild(deleteAllbutton)\n",
              "                div.appendChild(document.createElement('br'))\n",
              "                div.appendChild(brdiv)\n",
              "                div.appendChild(submit)\n",
              "                document.querySelector(\"#output-area\").appendChild(div);\n",
              "                return\n",
              "            }"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"6e7c3784-5977-11eb-af40-0242ac1c0002\"] = google.colab.output.getActiveOutputArea();\n",
              "//# sourceURL=js_21321b080c"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"6e7c9576-5977-11eb-af40-0242ac1c0002\"] = document.querySelector(\"#errorlog\");\n",
              "//# sourceURL=js_a8f9892883"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"6e7cde8c-5977-11eb-af40-0242ac1c0002\"] = google.colab.output.setActiveOutputArea(window[\"6e7c9576-5977-11eb-af40-0242ac1c0002\"]);\n",
              "//# sourceURL=js_7d3d502940"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'--boxes array populated--'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"6e7d48ae-5977-11eb-af40-0242ac1c0002\"] = google.colab.output.setActiveOutputArea(window[\"6e7c3784-5977-11eb-af40-0242ac1c0002\"]);\n",
              "//# sourceURL=js_ff0eb5fcba"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"7249e776-5977-11eb-af40-0242ac1c0002\"] = google.colab.output.getActiveOutputArea();\n",
              "//# sourceURL=js_f0e6e62198"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"724a3a82-5977-11eb-af40-0242ac1c0002\"] = document.querySelector(\"#errorlog\");\n",
              "//# sourceURL=js_89e269f4f6"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"724a72d6-5977-11eb-af40-0242ac1c0002\"] = google.colab.output.setActiveOutputArea(window[\"724a3a82-5977-11eb-af40-0242ac1c0002\"]);\n",
              "//# sourceURL=js_af703a7a16"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'--boxes array populated--'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"724b300e-5977-11eb-af40-0242ac1c0002\"] = google.colab.output.setActiveOutputArea(window[\"7249e776-5977-11eb-af40-0242ac1c0002\"]);\n",
              "//# sourceURL=js_930c147e9f"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"739e8852-5977-11eb-af40-0242ac1c0002\"] = google.colab.output.getActiveOutputArea();\n",
              "//# sourceURL=js_39345ae186"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"739f2be0-5977-11eb-af40-0242ac1c0002\"] = document.querySelector(\"#errorlog\");\n",
              "//# sourceURL=js_68bdda436a"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"73a0374c-5977-11eb-af40-0242ac1c0002\"] = google.colab.output.setActiveOutputArea(window[\"739f2be0-5977-11eb-af40-0242ac1c0002\"]);\n",
              "//# sourceURL=js_819c928d81"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'--boxes array populated--'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"73a098e0-5977-11eb-af40-0242ac1c0002\"] = google.colab.output.setActiveOutputArea(window[\"739e8852-5977-11eb-af40-0242ac1c0002\"]);\n",
              "//# sourceURL=js_355de5fbda"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"7e3cfa78-5977-11eb-af40-0242ac1c0002\"] = google.colab.output.getActiveOutputArea();\n",
              "//# sourceURL=js_b16dad1e30"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"7e3d3f1a-5977-11eb-af40-0242ac1c0002\"] = document.querySelector(\"#errorlog\");\n",
              "//# sourceURL=js_30d7f9cd48"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"7e3d8e84-5977-11eb-af40-0242ac1c0002\"] = google.colab.output.setActiveOutputArea(window[\"7e3d3f1a-5977-11eb-af40-0242ac1c0002\"]);\n",
              "//# sourceURL=js_2222335a15"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'--boxes array populated--'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"7e3e199e-5977-11eb-af40-0242ac1c0002\"] = google.colab.output.setActiveOutputArea(window[\"7e3cfa78-5977-11eb-af40-0242ac1c0002\"]);\n",
              "//# sourceURL=js_ed05027731"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"85f634aa-5977-11eb-af40-0242ac1c0002\"] = google.colab.output.getActiveOutputArea();\n",
              "//# sourceURL=js_b077199037"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"85f68130-5977-11eb-af40-0242ac1c0002\"] = document.querySelector(\"#errorlog\");\n",
              "//# sourceURL=js_d56e7437e5"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"85f6c956-5977-11eb-af40-0242ac1c0002\"] = google.colab.output.setActiveOutputArea(window[\"85f68130-5977-11eb-af40-0242ac1c0002\"]);\n",
              "//# sourceURL=js_dd4172f4b7"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'--boxes array populated--'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"85f7eaac-5977-11eb-af40-0242ac1c0002\"] = google.colab.output.setActiveOutputArea(window[\"85f634aa-5977-11eb-af40-0242ac1c0002\"]);\n",
              "//# sourceURL=js_05849878c3"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"df945a28-5977-11eb-af40-0242ac1c0002\"] = google.colab.output.getActiveOutputArea();\n",
              "//# sourceURL=js_791ef6f14f"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"df94aca8-5977-11eb-af40-0242ac1c0002\"] = document.querySelector(\"#errorlog\");\n",
              "//# sourceURL=js_2708c270c2"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"df9540be-5977-11eb-af40-0242ac1c0002\"] = google.colab.output.setActiveOutputArea(window[\"df94aca8-5977-11eb-af40-0242ac1c0002\"]);\n",
              "//# sourceURL=js_c6a164636b"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'--boxes array populated--'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"df962b50-5977-11eb-af40-0242ac1c0002\"] = google.colab.output.setActiveOutputArea(window[\"df945a28-5977-11eb-af40-0242ac1c0002\"]);\n",
              "//# sourceURL=js_24ae9e06b7"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SA8vBzhu079o",
        "outputId": "9d09f9ec-cc00-4ccd-d44f-307a2c3569d4"
      },
      "source": [
        "black_olive_class_id = 1\r\n",
        "num_classes = 1\r\n",
        "category_index = {black_olive_class_id: {'id': black_olive_class_id, 'name': 'black_olive'}}\r\n",
        "\r\n",
        "label_id_offset = 1\r\n",
        "train_image_tensors = []\r\n",
        "gt_classes_one_hot_tensors = []\r\n",
        "gt_box_tensors = []\r\n",
        "for (train_image_np, gt_box_np) in zip(\r\n",
        "    train_images_np, gt_boxes):\r\n",
        "  train_image_tensors.append(tf.expand_dims(tf.convert_to_tensor(\r\n",
        "      train_image_np, dtype=tf.float32), axis=0))\r\n",
        "  gt_box_tensors.append(tf.convert_to_tensor(gt_box_np, dtype=tf.float32))\r\n",
        "  zero_indexed_groundtruth_classes = tf.convert_to_tensor(\r\n",
        "      np.ones(shape=[gt_box_np.shape[0]], dtype=np.int32) - label_id_offset)\r\n",
        "  gt_classes_one_hot_tensors.append(tf.one_hot(\r\n",
        "      zero_indexed_groundtruth_classes, num_classes))\r\n",
        "print('Done prepping data.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[0.59666667, 0.39666667, 0.67      , 0.55      ]]), array([[0.49666667, 0.43666667, 0.58      , 0.54333333]]), array([[0.54333333, 0.39      , 0.695     , 0.57666667]]), array([[0.47166667, 0.41666667, 0.53333333, 0.52666667]]), array([[0.395     , 0.42666667, 0.50666667, 0.52666667]]), array([[0.71666667, 0.73333333, 0.80166667, 0.86      ]]), array([[0.63166667, 0.47333333, 0.69166667, 0.58      ]]), array([[0.41333333, 0.23666667, 0.49833333, 0.32333333]]), array([[0.64833333, 0.42333333, 0.69666667, 0.5       ]]), array([[0.635     , 0.51666667, 0.68833333, 0.59333333]]), array([[0.47666667, 0.49      , 0.52833333, 0.57      ]]), array([[0.48666667, 0.51      , 0.54666667, 0.61666667],\n",
            "       [0.56833333, 0.50333333, 0.56833333, 0.50333333]]), array([[0.52333333, 0.38      , 0.62333333, 0.54333333]]), array([[0.485     , 0.45      , 0.58333333, 0.59333333]]), array([[0.55166667, 0.44333333, 0.66166667, 0.60666667]]), array([[0.44333333, 0.36      , 0.56333333, 0.56333333]]), array([[0.50833333, 0.32666667, 0.625     , 0.53      ]]), array([[0.47666667, 0.40333333, 0.57833333, 0.58666667]]), array([[0.58666667, 0.51      , 0.66      , 0.62333333]])]\n",
            "Done prepping data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRt8qR921RZ7"
      },
      "source": [
        "dummy_scores = np.array([1.0], dtype=np.float32)\r\n",
        "\r\n",
        "plt.figure(figsize=(30, 15))\r\n",
        "# for idx in range(20):\r\n",
        "#   plt.subplot(4, 5, idx+1)\r\n",
        "#   plot_detections(\r\n",
        "#       train_images_np[idx],\r\n",
        "#       gt_boxes[idx],\r\n",
        "#       np.ones(shape=[gt_boxes[idx].shape[0]], dtype=np.int32),\r\n",
        "#       dummy_scores, category_index)\r\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_VTeFSp1T6n"
      },
      "source": [
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\r\n",
        "!tar -xf ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\r\n",
        "!mv ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint '/content/drive/MyDrive/Colab Notebooks/Olive Separation/models/research/object_detection/test_data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce7siiGZ1cKm",
        "outputId": "46054805-b571-4c16-d3db-56ca9b809672"
      },
      "source": [
        "tf.keras.backend.clear_session()\r\n",
        "\r\n",
        "print('Building model and restoring weights for fine-tuning...', flush=True)\r\n",
        "num_classes = 1\r\n",
        "pipeline_config = '/content/drive/MyDrive/Colab Notebooks/Olive Separation/models/research/object_detection/configs/tf2/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.config'\r\n",
        "checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/Olive Separation/models/research/object_detection/test_data/checkpoint/ckpt-0'\r\n",
        "\r\n",
        "configs = config_util.get_configs_from_pipeline_file(pipeline_config)\r\n",
        "model_config = configs['model']\r\n",
        "model_config.ssd.num_classes = num_classes\r\n",
        "model_config.ssd.freeze_batchnorm = True\r\n",
        "detection_model = model_builder.build(\r\n",
        "      model_config=model_config, is_training=True)\r\n",
        "\r\n",
        "fake_box_predictor = tf.compat.v2.train.Checkpoint(\r\n",
        "    _base_tower_layers_for_heads=detection_model._box_predictor._base_tower_layers_for_heads,\r\n",
        "    _box_prediction_head=detection_model._box_predictor._box_prediction_head,\r\n",
        "    )\r\n",
        "fake_model = tf.compat.v2.train.Checkpoint(\r\n",
        "          _feature_extractor=detection_model._feature_extractor,\r\n",
        "          _box_predictor=fake_box_predictor)\r\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=fake_model)\r\n",
        "ckpt.restore(checkpoint_path).expect_partial()\r\n",
        "\r\n",
        "image, shapes = detection_model.preprocess(tf.zeros([1, 640, 640, 3]))\r\n",
        "prediction_dict = detection_model.predict(image, shapes)\r\n",
        "_ = detection_model.postprocess(prediction_dict, shapes)\r\n",
        "print('Weights restored!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building model and restoring weights for fine-tuning...\n",
            "Weights restored!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwtwXTyb1fEE"
      },
      "source": [
        "tf.keras.backend.set_learning_phase(True)\r\n",
        "\r\n",
        "batch_size = 4\r\n",
        "learning_rate = 0.01\r\n",
        "num_batches = 100\r\n",
        "\r\n",
        "trainable_variables = detection_model.trainable_variables\r\n",
        "to_fine_tune = []\r\n",
        "prefixes_to_train = [\r\n",
        "  'WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead',\r\n",
        "  'WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead']\r\n",
        "for var in trainable_variables:\r\n",
        "  if any([var.name.startswith(prefix) for prefix in prefixes_to_train]):\r\n",
        "    to_fine_tune.append(var)\r\n",
        "\r\n",
        "def get_model_train_step_function(model, optimizer, vars_to_fine_tune):\r\n",
        "  \"\"\"Get a tf.function for training step.\"\"\"\r\n",
        "\r\n",
        "  @tf.function\r\n",
        "  def train_step_fn(image_tensors,\r\n",
        "                    groundtruth_boxes_list,\r\n",
        "                    groundtruth_classes_list):\r\n",
        "    \"\"\"A single training iteration.\r\n",
        "\r\n",
        "    Args:\r\n",
        "      image_tensors: A list of [1, height, width, 3] Tensor of type tf.float32.\r\n",
        "        Note that the height and width can vary across images, as they are\r\n",
        "        reshaped within this function to be 640x640.\r\n",
        "      groundtruth_boxes_list: A list of Tensors of shape [N_i, 4] with type\r\n",
        "        tf.float32 representing groundtruth boxes for each image in the batch.\r\n",
        "      groundtruth_classes_list: A list of Tensors of shape [N_i, num_classes]\r\n",
        "        with type tf.float32 representing groundtruth boxes for each image in\r\n",
        "        the batch.\r\n",
        "\r\n",
        "    Returns:\r\n",
        "      A scalar tensor representing the total loss for the input batch.\r\n",
        "    \"\"\"\r\n",
        "    shapes = tf.constant(batch_size * [[640, 640, 3]], dtype=tf.int32)\r\n",
        "    model.provide_groundtruth(\r\n",
        "        groundtruth_boxes_list=groundtruth_boxes_list,\r\n",
        "        groundtruth_classes_list=groundtruth_classes_list)\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "      preprocessed_images = tf.concat(\r\n",
        "          [detection_model.preprocess(image_tensor)[0]\r\n",
        "           for image_tensor in image_tensors], axis=0)\r\n",
        "      prediction_dict = model.predict(preprocessed_images, shapes)\r\n",
        "      losses_dict = model.loss(prediction_dict, shapes)\r\n",
        "      total_loss = losses_dict['Loss/localization_loss'] + losses_dict['Loss/classification_loss']\r\n",
        "      gradients = tape.gradient(total_loss, vars_to_fine_tune)\r\n",
        "      optimizer.apply_gradients(zip(gradients, vars_to_fine_tune))\r\n",
        "    return total_loss\r\n",
        "\r\n",
        "  return train_step_fn\r\n",
        "\r\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\r\n",
        "train_step_fn = get_model_train_step_function(\r\n",
        "    detection_model, optimizer, to_fine_tune)\r\n",
        "\r\n",
        "print('Start fine-tuning!', flush=True)\r\n",
        "for idx in range(num_batches):\r\n",
        "  all_keys = list(range(len(train_images_np)))\r\n",
        "  random.shuffle(all_keys)\r\n",
        "  example_keys = all_keys[:batch_size]\r\n",
        "\r\n",
        "  gt_boxes_list = [gt_box_tensors[key] for key in example_keys]\r\n",
        "  gt_classes_list = [gt_classes_one_hot_tensors[key] for key in example_keys]\r\n",
        "  image_tensors = [train_image_tensors[key] for key in example_keys]\r\n",
        "\r\n",
        "  total_loss = train_step_fn(image_tensors, gt_boxes_list, gt_classes_list)\r\n",
        "\r\n",
        "  if idx % 10 == 0:\r\n",
        "    print('batch ' + str(idx) + ' of ' + str(num_batches)\r\n",
        "    + ', loss=' +  str(total_loss.numpy()), flush=True)\r\n",
        "\r\n",
        "print('Done fine-tuning!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IMh0B7c51m_O"
      },
      "source": [
        "test_image_dir = '/content/drive/MyDrive/Colab Notebooks/Olive Separation/models/research/object_detection/images/test/'\r\n",
        "test_images_np = []\r\n",
        "for i in (3, 10, 11, 16, 18):\r\n",
        "  image_path = os.path.join(test_image_dir, 'out' + str(i) + '.jpg')\r\n",
        "  test_images_np.append(np.expand_dims(\r\n",
        "      load_image_into_numpy_array(image_path), axis=0))\r\n",
        "\r\n",
        "@tf.function\r\n",
        "def detect(input_tensor):\r\n",
        "  \"\"\"Run detection on an input image.\r\n",
        "\r\n",
        "  Args:\r\n",
        "    input_tensor: A [1, height, width, 3] Tensor of type tf.float32.\r\n",
        "      Note that height and width can be anything since the image will be\r\n",
        "      immediately resized according to the needs of the model within this\r\n",
        "      function.\r\n",
        "\r\n",
        "  Returns:\r\n",
        "    A dict containing 3 Tensors (`detection_boxes`, `detection_classes`,\r\n",
        "      and `detection_scores`).\r\n",
        "  \"\"\"\r\n",
        "  preprocessed_image, shapes = detection_model.preprocess(input_tensor)\r\n",
        "  prediction_dict = detection_model.predict(preprocessed_image, shapes)\r\n",
        "  return detection_model.postprocess(prediction_dict, shapes)\r\n",
        "\r\n",
        "label_id_offset = 1\r\n",
        "for i in range(len(test_images_np)):\r\n",
        "  input_tensor = tf.convert_to_tensor(test_images_np[i], dtype=tf.float32)\r\n",
        "  detections = detect(input_tensor)\r\n",
        "\r\n",
        "  plot_detections(\r\n",
        "      test_images_np[i][0],\r\n",
        "      detections['detection_boxes'][0].numpy(),\r\n",
        "      detections['detection_classes'][0].numpy().astype(np.uint32)\r\n",
        "      + label_id_offset,\r\n",
        "      detections['detection_scores'][0].numpy(),\r\n",
        "      category_index, figsize=(15, 20), image_name=\"gif_frame_\" + ('%02d' % i) + \".jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}